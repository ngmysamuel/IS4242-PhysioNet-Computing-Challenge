{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IS4242 Group Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import necessary libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ensure that you are in the root folder of all the fold folders and target files\n",
    "read_text(fold_name):\n",
    "    fold_name: this is the name of the fold you want to read ALL patient files of. It will be read into a 2 dimensional\n",
    "    list. If you would like to retrieve just the first patient instead, you will need to change the line \n",
    "    \"txt_all.extend(txt[1:])\" to \"txt_all.append(txt[1:])\" and you will be to use \"read_text(fold1.txt)[0]\" to retrieve\n",
    "    the relevant patient's data\n",
    "read_ans(file_name):\n",
    "    file_name: this is the name of the file you want to read ALL targets of. It will be read into a 2 dimensional\n",
    "    list. To retrieve the first patient's target: read_ans(ans.csv)[0]\n",
    "put_single_into_dataframe(txt): This functions takes in 2 dimensional list ie the output of read_text(fold1.txt) \n",
    "put_multiple_into_dataframe(txt): Multiple is for using it with the output of read_text after you wanted to change it to append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(fold_name):\n",
    "    txt_all = list()\n",
    "    for f in os.listdir(fold_name): # for each file in the directory\n",
    "        if f.endswith(\".txt\"):\n",
    "            with open(os.path.join(fold_name, f), 'r') as fp: # open each file\n",
    "                txt = fp.readlines() # read inside the file\n",
    "                recordid = txt[1].rstrip('\\n').split(',')[-1] # get recordid\n",
    "                txt = [[int(recordid)] + t.rstrip('\\n').split(',') for t in txt] # preface each row with the recordid as all patients are 1 file\n",
    "                txt_all.extend(txt[1:]) # skip the parameter list\n",
    "    return txt_all\n",
    "\n",
    "def read_one_text(fold_name):\n",
    "    txt_all = list()\n",
    "    for f in os.listdir(fold_name): # for each file in the directory\n",
    "        if f.endswith(\".txt\"):\n",
    "            with open(os.path.join(fold_name, f), 'r') as fp: # open each file\n",
    "                txt = fp.readlines() # read inside the file\n",
    "            recordid = txt[1].rstrip('\\n').split(',')[-1] # get recordid\n",
    "            txt = [[int(recordid)] + t.rstrip('\\n').split(',') for t in txt] # preface each row with the recordid as all patients are 1 file\n",
    "            txt_all.append(txt[1:]) # skip the parameter list\n",
    "    return txt_all\n",
    "\n",
    "def read_ans(file_name):\n",
    "    txt_all = list()\n",
    "    with open(file_name, 'r') as fp: # opens the csv file\n",
    "        txt = fp.readlines() \n",
    "    for i in range(1, len(txt)): # similar to above read_text\n",
    "        record_id, length_of_stay, hospital_death = txt[i].rstrip('\\n').split(',')\n",
    "        txt_all.append([record_id, length_of_stay, hospital_death])\n",
    "    return txt_all\n",
    "\n",
    "def put_multiple_into_dataframe(txt_all):\n",
    "    df = pd.DataFrame()\n",
    "    for i in txt_all:\n",
    "        df2 = pd.DataFrame(i, columns=['recordid', 'time', 'parameter', 'value'])\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def put_single_into_dataframe(txt_all):\n",
    "    df = pd.DataFrame(txt_all, columns=['recordid', 'time', 'parameter', 'value'])\n",
    "    return df\n",
    "\n",
    "def get_X_add_ready(X_add, stat):\n",
    "    X_add = X_add.reset_index()\n",
    "    X_add = X_add.pivot(index='recordid', columns='parameter', values='value')\n",
    "    X_add = X_add.drop(stat_feat, axis = 1) \n",
    "#     X_add = X_add.drop(['RecordID'], axis = 1) \n",
    "    X_add.columns = [x+stat for x in X_add.columns]\n",
    "    X_add = X_add.reset_index()\n",
    "    return X_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Data Exploration</h1>\n",
    "<p>Will in add explanation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = read_one_text(\"../Project_Data/Fold1\")[0]\n",
    "p1df = pd.DataFrame(p1, columns=['recordid', 'time', 'parameter', 'value'])\n",
    "df_1 = p1df.drop('recordid', axis=1)\n",
    "df_1.drop(df_1.index[:1], inplace=True)\n",
    "# df_1\n",
    "\n",
    "df_1['value'] = pd.to_numeric(df_1['value'])\n",
    "df_1.time = df_1.time.astype('str')\n",
    "df_1['time'] = df_1['time'].str.replace(':', '.')\n",
    "df_1['time'] = pd.to_numeric(df_1['time'])\n",
    "df_1['time_value'] = list(zip(df_1.time, df_1.value))\n",
    "df_2 = df_1.groupby('parameter').time_value.apply(lambda x: x.unique().tolist())\n",
    "\n",
    "major_ticks = np.arange(0, 51, 10)\n",
    "minor_ticks = np.arange(0, 49, 2)\n",
    "fig = plt.figure(figsize=(18, 30))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i in range(len(df_2)):\n",
    "    testList2 = [(elem1, elem2) for elem1, elem2 in df_2[i]]\n",
    "    zip(*testList2)\n",
    "    plt.plot(*zip(*testList2), marker='o', label=df_2.index[i])\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.xlim(xmin=0.0)\n",
    "# plt.ylim(ymin=0.0)\n",
    "ax.minorticks_on()\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "\n",
    "ax.grid(which='minor', alpha=0.2)\n",
    "ax.grid(which='major', alpha=0.5)\n",
    "# ax.tick_params(which = 'both', direction = 'out')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordid</th>\n",
       "      <th>time</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>00:00</td>\n",
       "      <td>RecordID</td>\n",
       "      <td>132539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Age</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Height</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539</td>\n",
       "      <td>00:00</td>\n",
       "      <td>ICUType</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordid   time parameter   value\n",
       "0    132539  00:00  RecordID  132539\n",
       "1    132539  00:00       Age      54\n",
       "2    132539  00:00    Gender       0\n",
       "3    132539  00:00    Height      -1\n",
       "4    132539  00:00   ICUType       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame()\n",
    "numberOfFolds = 0\n",
    "for i, name in enumerate([\"Fold1\"]): # what folds do you want to use?\n",
    "    string = \"../Project_Data/\"\n",
    "    string += name\n",
    "    df_feat = df_feat.append(put_single_into_dataframe(read_text(string)))\n",
    "    numberOfFolds = (i+1)\n",
    "numberOfRows = numberOfFolds*1000\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordid</th>\n",
       "      <th>days_in_hospital</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132540</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132541</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132543</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132545</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recordid days_in_hospital mortality\n",
       "0   132539                5         0\n",
       "1   132540                8         0\n",
       "2   132541               19         0\n",
       "3   132543                9         0\n",
       "4   132545                4         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Target\n",
    "df_target = pd.DataFrame(read_ans('../Project_Data/Fold1_Outcomes.csv'), columns=['recordid', 'days_in_hospital', 'mortality'])\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of record ids: 1000\n",
      "HR             57.027\n",
      "MAP            36.092\n",
      "SysABP         35.979\n",
      "DiasABP        35.955\n",
      "Urine          34.208\n",
      "Weight         33.679\n",
      "NISysABP       24.457\n",
      "NIDiasABP      24.424\n",
      "NIMAP          24.088\n",
      "Temp           21.204\n",
      "GCS            15.214\n",
      "RespRate       13.775\n",
      "FiO2            7.815\n",
      "MechVent        7.596\n",
      "pH              5.770\n",
      "PaO2            5.496\n",
      "PaCO2           5.490\n",
      "HCT             4.626\n",
      "K               3.708\n",
      "Creatinine      3.573\n",
      "Platelets       3.566\n",
      "BUN             3.547\n",
      "HCO3            3.479\n",
      "Mg              3.468\n",
      "Na              3.462\n",
      "Glucose         3.338\n",
      "WBC             3.286\n",
      "SaO2            1.985\n",
      "Lactate         1.924\n",
      "Height          1.000\n",
      "ICUType         1.000\n",
      "Age             1.000\n",
      "RecordID        1.000\n",
      "Gender          1.000\n",
      "Bilirubin       0.858\n",
      "AST             0.857\n",
      "ALT             0.857\n",
      "ALP             0.833\n",
      "Albumin         0.617\n",
      "TroponinT       0.566\n",
      "TroponinI       0.130\n",
      "Cholesterol     0.077\n",
      "Name: parameter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bin_feat = ['MechVent']\n",
    "num_feat = ['Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol',\n",
    "           'Creatinine', 'DiasABP', 'FiO2', 'GCS', 'Glucose', 'HCO3', 'HCT',\n",
    "           'HR', 'K', 'Lactate', 'Mg', 'MAP', 'NA', 'NIDiasABP', 'NIMAP',\n",
    "           'NISysABP', 'PaCO2', 'PaO2', 'pH', 'Platelets', 'RespRate', 'SaO2',\n",
    "           'SysABP', 'Temp', 'Tropl', 'TropT', 'Urine', 'WBC', 'Weight']\n",
    "\n",
    "print(\"Number of record ids:\", len(df_feat['recordid'].unique()))\n",
    "unique_count = df_feat['parameter'].value_counts()/numberOfRows\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analysis of Features</h2>\n",
    "<p>The data above shows the average number of times a variable observed per patient. Based on the data above and the feature description we classify the features into these categories:\n",
    "<ul>\n",
    "    <li>General Descriptors (static data) that are collected when the patient is admitted to the ICU. Weight is not included as weight are measured multiple times as a time series data. Each of the descriptors will be included as a feature into the model.</li>\n",
    "    <li>Rare features: measured on average less than one time per patient (less than 1.0). We use the <u>existence</u> of these measurements for each patient as a feature.</li>\n",
    "    <li>Features that measured often or more that one time per patient (more than 1.0). Calculate the hourly average of each measurements and put them into 48 columns. <i>Example, average HR on the first hour to HR_1, average HR on the second hour to HR_2, and so on.</i></li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare features ['Bilirubin', 'AST', 'ALT', 'ALP', 'Albumin', 'TroponinT', 'TroponinI', 'Cholesterol', 'MechVent']\n",
      "Normal features ['HR', 'MAP', 'SysABP', 'DiasABP', 'Urine', 'Weight', 'NISysABP', 'NIDiasABP', 'NIMAP', 'Temp', 'GCS', 'RespRate', 'FiO2', 'MechVent', 'pH', 'PaO2', 'PaCO2', 'HCT', 'K', 'Creatinine', 'Platelets', 'BUN', 'HCO3', 'Mg', 'Na', 'Glucose', 'WBC', 'SaO2', 'Lactate']\n"
     ]
    }
   ],
   "source": [
    "stat_feat = ['Age', 'Gender', 'Height', 'ICUType', 'RecordID'] #General Descriptors\n",
    "rare_feat = []\n",
    "nor_feat = []\n",
    "for index, value in unique_count.items():\n",
    "    if value < 1.0:\n",
    "        rare_feat.append(index)\n",
    "    elif index not in stat_feat:\n",
    "        nor_feat.append(index)\n",
    "rare_feat.append(\"MechVent\")\n",
    "print(\"Rare features\", rare_feat)\n",
    "print(\"Normal features\", nor_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code to produce test and train data\n",
    "df = df_feat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creation of Data Matrices</h2>\n",
    "<p>We create 3 different matrices to convert temporal data into a matrix that is a single feature vector per patient </p>\n",
    "<ul> \n",
    "    <li>First, in the cell below, we create a matrix that generalises a patient's attributes across the whole 48 hours, such as his max BUN measurement over the 48 hours. </li>\n",
    "    <li>Second, Junhao what is your matrix? (Will add in soon)</li>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x_for_design_matrix_1(df_feat):\n",
    "    non_bin_feat.clear()\n",
    "    # your code to produce test and train data\n",
    "    df = df_feat.copy()\n",
    "\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    temp_df = df.loc[df['time'] == '00:00', :].copy() # get all the variables at time 0\n",
    "    temp_df = temp_df.loc[temp_df['parameter'].isin(stat_feat)] # prune the dataframe to only those static variables\n",
    "    temp_df = temp_df.pivot(index='recordid', columns='parameter', values='value') \n",
    "    temp_df = temp_df.reset_index()\n",
    "    for i in temp_df: # for loop to change all the -1 values for static variables into np.nan\n",
    "        idx = temp_df.index[temp_df[i] == -1].tolist()\n",
    "        for j in idx:\n",
    "            temp_df.loc[j, i] = np.nan\n",
    "    final_df = temp_df.copy()\n",
    "\n",
    "#     Dealing with rare_feat\n",
    "    d = df_feat.groupby(['recordid', 'parameter'])[['value']].count()\n",
    "    def specialFeature(special):\n",
    "        id = []\n",
    "        for index, row in d.iterrows():\n",
    "            if index[1] == special:\n",
    "                id.append(index[0])\n",
    "        return id\n",
    "    for x in rare_feat:\n",
    "        id = specialFeature(x)\n",
    "        final_df[x] = 0\n",
    "        for i in id:\n",
    "            for row in final_df.index:\n",
    "                if row == i:\n",
    "                    final_df.loc[row, x] = 1\n",
    "    final_df = final_df.drop([\"RecordID\"],axis=1)\n",
    "\n",
    "    # Getting the different attributes\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    temp_df = df.drop(df.index[df['parameter'].isin(rare_feat)].tolist())\n",
    "    temp_df = temp_df.groupby(['recordid', 'parameter'])[['value']]\n",
    "    for i in ['min', 'max', 'mean']: # the different parameters we will use\n",
    "        if (i=='min'):\n",
    "            X_add = temp_df.min() # get the min of each parameter\n",
    "            X_add = get_X_add_ready(X_add, '_min')\n",
    "            final_df = final_df.merge(X_add, left_on='recordid', right_on='recordid') # merge the min of the parameters to the final dataframe\n",
    "        elif (i=='max'):\n",
    "            X_add = temp_df.max() # get the max of each parameter\n",
    "            X_add = get_X_add_ready(X_add, '_max')\n",
    "            final_df = final_df.merge(X_add, left_on='recordid', right_on='recordid') # merge the min of the parameters to the final dataframe\n",
    "        elif (i=='mean'):\n",
    "            X_add = temp_df.mean() # get the mean of each parameter\n",
    "            X_add = get_X_add_ready(X_add, '_mean')\n",
    "            final_df = final_df.merge(X_add, left_on='recordid', right_on='recordid') # merge the min of the parameters to the final dataframe\n",
    "\n",
    "    # dealing with ICUType categorical\n",
    "    one_hot = pd.get_dummies(final_df['ICUType'])\n",
    "    meaning_of_icu_types = {1:'Coronary Care Unit', 2: 'Cardiac Surgery Recovery Unit', 3: 'Medical ICU', 4: 'Surgical ICU'}\n",
    "    one_hot.columns = [meaning_of_icu_types[x] for x in one_hot.columns]\n",
    "    final_df = final_df.merge(one_hot, left_index=True, right_index=True)\n",
    "    final_df = final_df.drop('ICUType', axis=1)\n",
    "    \n",
    "    # Extreme height values is set to np.nan\n",
    "    for index, row in final_df.iterrows():\n",
    "        if row[\"Height\"] < 40 or row[\"Height\"] > 210:\n",
    "            row[\"Height\"] = np.nan\n",
    "\n",
    "\n",
    "    # Drop recordID column\n",
    "    final_df = final_df.drop(\"recordid\", axis=1)\n",
    "            \n",
    "    # Creating non binary column list and filling na values with mean\n",
    "    for i in final_df:\n",
    "        if i in rare_feat or i in bin_feat:\n",
    "            continue\n",
    "        final_df = final_df.fillna(final_df.mean())\n",
    "        non_bin_feat.append(i)\n",
    "        \n",
    "#     display(final_df.head())\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Matrix\n",
    "def preprocess_x_for_design_matrix_2(df):\n",
    "    non_bin_feat.clear()\n",
    "    \n",
    "    df_static = df.loc[df['time'] == '00:00', :].copy()\n",
    "    static_vars = ['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight']\n",
    "    df_static.drop('time', axis=1, inplace=True)\n",
    "    df_static = df_static.loc[df_static['parameter'].isin(static_vars)]\n",
    "    df_static = df_static.groupby(['recordid', 'parameter'])[['value']].last()\n",
    "    df_static.reset_index(inplace=True)\n",
    "    df_static = df_static.pivot(index='recordid', columns='parameter', values='value')\n",
    "\n",
    "    for c in df_static.columns:\n",
    "        df_static[c] = pd.to_numeric(df_static[c])\n",
    "\n",
    "    for c in df_static.columns:\n",
    "        x = df_static[c]\n",
    "        if c == 'Height':\n",
    "            idx = x < 0\n",
    "            df_static.loc[idx, c] = np.nan\n",
    "        elif c == 'Weight':\n",
    "            idx = x < 0\n",
    "            df_static.loc[idx, c] = np.nan\n",
    "    d = df.groupby(['recordid', 'parameter'])[['value']].count()\n",
    "    def specialFeature(special):\n",
    "        id = []\n",
    "        for index, row in d.iterrows():\n",
    "            if index[1] == special:\n",
    "                id.append(index[0])\n",
    "        return id\n",
    "\n",
    "    df2 = df_static.copy()\n",
    "    df2.drop('RecordID', axis=1, inplace=True)\n",
    "\n",
    "    for x in rare_feat:\n",
    "        id = specialFeature(x)\n",
    "        df2[x] = 0\n",
    "        for i in id:\n",
    "            for row in df2.index:\n",
    "                if row == i:\n",
    "                    df2.loc[row, x] = 1\n",
    "    df2.head()\n",
    "    normal_feat = nor_feat.copy()\n",
    "    normal_feat.remove('MechVent')\n",
    "    idx = df['parameter'].isin(normal_feat)\n",
    "    df3 = df.loc[idx, :].copy()\n",
    "    df3[['hour','min']] = df3.time.str.split(':', expand=True)\n",
    "    df3[\"hour\"] = pd.to_numeric(df3[\"hour\"])\n",
    "    df3[\"value\"] = pd.to_numeric(df3[\"value\"])\n",
    "    bins = [0, 12, 24, 36, 48]\n",
    "    labels = ['0', '12', '24', '36']\n",
    "    df3 = df3.groupby(['recordid', pd.cut(df3.hour, bins=bins, labels=labels), 'parameter'])[['value']].mean()\n",
    "    df3\n",
    "\n",
    "    for n in normal_feat:    \n",
    "        df2[n +'0'] = np.nan\n",
    "        df2[n +'12'] = np.nan\n",
    "        df2[n +'24'] = np.nan\n",
    "        df2[n +'36'] = np.nan\n",
    "    df2.head()\n",
    "\n",
    "    for index, row in df3.iterrows():\n",
    "        recordId = index[0]\n",
    "        hour = index[1]\n",
    "        parameter = index[2]\n",
    "        df2.loc[recordId, parameter+hour] = row[\"value\"]\n",
    "\n",
    "    one_hot = pd.get_dummies(df2['ICUType'])\n",
    "    meaning_of_icu_types = {1:'Coronary Care Unit', 2: 'Cardiac Surgery Recovery Unit', 3: 'Medical ICU', 4: 'Surgical ICU'}\n",
    "    one_hot.columns = [meaning_of_icu_types[x] for x in one_hot.columns]\n",
    "    df2 = df2.merge(one_hot, left_index=True, right_index=True)\n",
    "    df2 = df2.drop('ICUType', axis=1)\n",
    "    \n",
    "    # Extreme height values is set to np.nan\n",
    "    for index, row in df2.iterrows():\n",
    "        if row[\"Height\"] < 40 or row[\"Height\"] > 210:\n",
    "            row[\"Height\"] = np.nan\n",
    "            \n",
    "    # Creating non binary column list and filling na values with mean\n",
    "    for i in df2:\n",
    "        if i in rare_feat or i in bin_feat:\n",
    "            continue\n",
    "        df2 = df2.fillna(df2.mean())\n",
    "        non_bin_feat.append(i)\n",
    "\n",
    "    display(df2.head())\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Building</h1>\n",
    "<p>We develop models for our design matrix.</p>\n",
    "<ul> \n",
    "    <li>First, in the cell below, we make use of the first design matrix above to pass in as input to the models. It mannually does cross validation on the 3 folds and validation on the remaining fold. Included is 3 regresssion models (Linear, DecisionTree, MLP) and 3 classification models (AdaboostedDecisionTrees, MLP, GaussianNB). Each utilises their own pipelines which makes use diffrent feature selectors </li>\n",
    "    <li>Second, it utilises the pipelines introduced in First on the second design matrix</li>\n",
    "    <li></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_feat = [\"Gender\", \"Coronary Care Unit\", \"Cardiac Surgery Recovery Unit\", \"Medical ICU\", \"Surgical ICU\"]\n",
    "non_bin_feat = []\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    remainder = 'passthrough',\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), non_bin_feat)])\n",
    "\n",
    "parameters = {'VarianceThreshold':[0,0.5], 'PCA':[60,70],\n",
    "              'SelectKBest':[80, 90],\n",
    "              'DecisionTreeRegressor_min_samples_leaf':[1,3],\n",
    "              'MLPRegressor_hiddenLayer':[(45,45,), (100,), (30,30,30)]\n",
    "             }\n",
    "\n",
    "all_list = [1,2,3,4]\n",
    "for i in range(1,5):\n",
    "    print(\"Testing on Fold\", i)\n",
    "    x_train_df = pd.DataFrame()\n",
    "    y_train_df = pd.DataFrame()\n",
    "    \n",
    "    # Getting train data set up\n",
    "    for j in [x for x in all_list if x != i]: \n",
    "        string = \"../Project_Data/Fold\"+str(j)\n",
    "        y_file = \"../Project_Data/Fold\"+str(j)+\"_Outcomes.csv\"\n",
    "        x_train_df = x_train_df.append(put_single_into_dataframe(read_text(string)))\n",
    "        y_train_df = y_train_df.append(pd.DataFrame(read_ans(y_file), columns=['recordid', 'days_in_hospital', 'mortality']))\n",
    "    x_train_df = preprocess_x_for_design_matrix_1(x_train_df)\n",
    "    y_linear_train_df = y_train_df.drop(['recordid','mortality'], axis=1)\n",
    "    for index, row in y_train_df.iterrows():\n",
    "        if row['days_in_hospital'] == -1:\n",
    "            row['days_in_hospital'] = 2\n",
    "    y_linear_train_df['days_in_hospital'] = pd.to_numeric(y_linear_train_df['days_in_hospital'])\n",
    "    y_classification_train_df = y_train_df.drop(['recordid','days_in_hospital'], axis=1)\n",
    "    y_classification_train_df['mortality'] = pd.to_numeric(y_classification_train_df['mortality'])\n",
    "        \n",
    "    # Getting test data set up\n",
    "    x_test_df = put_single_into_dataframe(read_text(\"../Project_Data/Fold\"+str(i)))\n",
    "    x_test_df = preprocess_x_for_design_matrix_1(x_test_df)\n",
    "    y_test_df = pd.DataFrame(read_ans(\"../Project_Data/Fold\"+str(i)+\"_Outcomes.csv\"), columns=['recordid', 'days_in_hospital', 'mortality'])\n",
    "    y_linear_test_df = y_test_df.drop(['recordid','mortality'], axis=1)\n",
    "    for index, row in y_test_df.iterrows():\n",
    "        if row['days_in_hospital'] == -1:\n",
    "            row['days_in_hospital'] = 2\n",
    "    y_linear_test_df['days_in_hospital'] = pd.to_numeric(y_linear_test_df['days_in_hospital'])\n",
    "    y_classification_test_df = y_test_df.drop(['recordid','days_in_hospital'], axis=1)\n",
    "    y_classification_test_df['mortality'] = pd.to_numeric(y_classification_test_df['mortality'])\n",
    "    \n",
    "    # Create classification model and parameters to try out\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', AdaBoostClassifier())])\n",
    "            est.fit(x_train_df, y_classification_train_df)\n",
    "            prediction = est.predict(x_test_df)\n",
    "            print ( \"Using AdaBoostClassifier --> VarianceThreshold: {} and PCA: {} has a score of {}\".format(nThreshold, nN_components, roc_auc_score(y_classification_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            for hiddenLayer in parameters[\"MLPRegressor_hiddenLayer\"]:\n",
    "                est = Pipeline(steps=[\n",
    "                    ('scaler', scaler),\n",
    "                    ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "                    ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                    ('classifier', MLPClassifier(hidden_layer_sizes = hiddenLayer))])\n",
    "                est.fit(x_train_df, y_classification_train_df)\n",
    "                prediction = est.predict(x_test_df)\n",
    "                print ( \"Using MLPClassifier --> HiddenLayer: {} VarianceThreshold: {} and PCA: {} has a score of {}\".format(hiddenLayer, nThreshold, nN_components, roc_auc_score(y_classification_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', GaussianNB())])\n",
    "            est.fit(x_train_df, y_classification_train_df)\n",
    "            prediction = est.predict(x_test_df)\n",
    "            print ( \"Using GaussianNB --> VarianceThreshold: {} and PCA: {} has a score of {}\".format(nThreshold, nN_components, roc_auc_score(y_classification_test_df, prediction)) )        \n",
    "    \n",
    "    # Creating regression model and parameters to try out\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            est = Pipeline(steps=[\n",
    "            ('scaler', scaler),\n",
    "            ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "            ('dim_reducer', PCA(n_components = nN_components)),\n",
    "            ('classifier', LinearRegression())])\n",
    "            est.fit(x_train_df, y_linear_train_df)\n",
    "            prediction = est.predict(x_test_df)\n",
    "            print ( \"Using LinearRegression --> VarianceThreshold: {} and PCA: {} has a score of {}\".format(nThreshold, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"SelectKBest\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            for min_samples_leaf in parameters[\"DecisionTreeRegressor_min_samples_leaf\"]:\n",
    "                est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', SelectKBest(k = 90)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', DecisionTreeRegressor(min_samples_leaf = min_samples_leaf))])\n",
    "                est.fit(x_train_df, y_linear_train_df)\n",
    "                prediction = est.predict(x_test_df)\n",
    "                print ( \"Using DecisionTreeRegressor({}) --> SelectKBest: 90 and PCA: {} has a score of {}\".format(min_samples_leaf, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            for hiddenLayer in parameters[\"MLPRegressor_hiddenLayer\"]:\n",
    "                est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', MLPRegressor(hidden_layer_sizes = hiddenLayer, learning_rate_init = 0.01))])\n",
    "                est.fit(x_train_df, y_linear_train_df)\n",
    "                prediction = est.predict(x_test_df)\n",
    "                print ( \"Using MLPRegressor({}) --> SelectKBest: 90 and PCA: {} has a score of {}\".format(hiddenLayer, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    print(end=\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO224</th>\n",
       "      <th>SaO236</th>\n",
       "      <th>Lactate0</th>\n",
       "      <th>Lactate12</th>\n",
       "      <th>Lactate24</th>\n",
       "      <th>Lactate36</th>\n",
       "      <th>Coronary Care Unit</th>\n",
       "      <th>Cardiac Surgery Recovery Unit</th>\n",
       "      <th>Medical ICU</th>\n",
       "      <th>Surgical ICU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recordid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135076</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.368618</td>\n",
       "      <td>96.356632</td>\n",
       "      <td>2.583674</td>\n",
       "      <td>2.30822</td>\n",
       "      <td>2.070263</td>\n",
       "      <td>2.008021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135077</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>169.685199</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.368618</td>\n",
       "      <td>96.356632</td>\n",
       "      <td>2.583674</td>\n",
       "      <td>2.30822</td>\n",
       "      <td>2.070263</td>\n",
       "      <td>2.008021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135079</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>169.685199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>96.368618</td>\n",
       "      <td>96.356632</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>2.30822</td>\n",
       "      <td>2.070263</td>\n",
       "      <td>2.008021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135080</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>170.200000</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.368618</td>\n",
       "      <td>96.356632</td>\n",
       "      <td>2.583674</td>\n",
       "      <td>2.80000</td>\n",
       "      <td>2.070263</td>\n",
       "      <td>2.008021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135081</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>162.600000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.368618</td>\n",
       "      <td>96.356632</td>\n",
       "      <td>2.583674</td>\n",
       "      <td>2.30822</td>\n",
       "      <td>2.070263</td>\n",
       "      <td>2.008021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender      Height  Weight  Bilirubin  AST  ALT  ALP  Albumin  \\\n",
       "recordid                                                                       \n",
       "135076     56       1  177.800000   110.0          1    1    1    1        0   \n",
       "135077     72       1  169.685199   220.0          0    0    0    0        1   \n",
       "135079     68       1  169.685199   100.0          0    0    0    0        0   \n",
       "135080     77       1  170.200000    77.5          0    0    0    0        0   \n",
       "135081     66       1  162.600000    65.0          0    0    0    0        0   \n",
       "\n",
       "          TroponinT  ...     SaO224     SaO236  Lactate0  Lactate12  \\\n",
       "recordid             ...                                              \n",
       "135076            0  ...  96.368618  96.356632  2.583674    2.30822   \n",
       "135077            0  ...  96.368618  96.356632  2.583674    2.30822   \n",
       "135079            1  ...  96.368618  96.356632  1.700000    2.30822   \n",
       "135080            0  ...  96.368618  96.356632  2.583674    2.80000   \n",
       "135081            0  ...  96.368618  96.356632  2.583674    2.30822   \n",
       "\n",
       "          Lactate24  Lactate36  Coronary Care Unit  \\\n",
       "recordid                                             \n",
       "135076     2.070263   2.008021                   0   \n",
       "135077     2.070263   2.008021                   0   \n",
       "135079     2.070263   2.008021                   0   \n",
       "135080     2.070263   2.008021                   0   \n",
       "135081     2.070263   2.008021                   0   \n",
       "\n",
       "          Cardiac Surgery Recovery Unit  Medical ICU  Surgical ICU  \n",
       "recordid                                                            \n",
       "135076                                0            0             1  \n",
       "135077                                0            1             0  \n",
       "135079                                0            0             1  \n",
       "135080                                1            0             0  \n",
       "135081                                1            0             0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>ALP</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO224</th>\n",
       "      <th>SaO236</th>\n",
       "      <th>Lactate0</th>\n",
       "      <th>Lactate12</th>\n",
       "      <th>Lactate24</th>\n",
       "      <th>Lactate36</th>\n",
       "      <th>Coronary Care Unit</th>\n",
       "      <th>Cardiac Surgery Recovery Unit</th>\n",
       "      <th>Medical ICU</th>\n",
       "      <th>Surgical ICU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recordid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132539</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>170.094476</td>\n",
       "      <td>81.422068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.396396</td>\n",
       "      <td>96.604748</td>\n",
       "      <td>2.575443</td>\n",
       "      <td>2.395522</td>\n",
       "      <td>2.447271</td>\n",
       "      <td>2.711155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132540</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>175.300000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.396396</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>2.575443</td>\n",
       "      <td>2.395522</td>\n",
       "      <td>2.447271</td>\n",
       "      <td>2.711155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132541</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>170.094476</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.396396</td>\n",
       "      <td>96.604748</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.711155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132543</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>180.300000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.396396</td>\n",
       "      <td>96.604748</td>\n",
       "      <td>2.575443</td>\n",
       "      <td>2.395522</td>\n",
       "      <td>2.447271</td>\n",
       "      <td>2.711155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132545</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>170.094476</td>\n",
       "      <td>81.422068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.396396</td>\n",
       "      <td>96.604748</td>\n",
       "      <td>2.575443</td>\n",
       "      <td>2.395522</td>\n",
       "      <td>2.447271</td>\n",
       "      <td>2.711155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender      Height     Weight  Bilirubin  AST  ALT  ALP  \\\n",
       "recordid                                                                 \n",
       "132539     54       0  170.094476  81.422068          0    0    0    0   \n",
       "132540     76       1  175.300000  76.000000          0    0    0    0   \n",
       "132541     44       0  170.094476  56.700000          1    1    1    1   \n",
       "132543     68       1  180.300000  84.600000          1    1    1    1   \n",
       "132545     88       0  170.094476  81.422068          0    0    0    0   \n",
       "\n",
       "          Albumin  TroponinT  ...     SaO224     SaO236  Lactate0  Lactate12  \\\n",
       "recordid                      ...                                              \n",
       "132539          0          0  ...  96.396396  96.604748  2.575443   2.395522   \n",
       "132540          0          0  ...  96.396396  95.000000  2.575443   2.395522   \n",
       "132541          1          0  ...  96.396396  96.604748  1.300000   1.900000   \n",
       "132543          1          0  ...  96.396396  96.604748  2.575443   2.395522   \n",
       "132545          1          0  ...  96.396396  96.604748  2.575443   2.395522   \n",
       "\n",
       "          Lactate24  Lactate36  Coronary Care Unit  \\\n",
       "recordid                                             \n",
       "132539     2.447271   2.711155                   0   \n",
       "132540     2.447271   2.711155                   0   \n",
       "132541     0.900000   2.711155                   0   \n",
       "132543     2.447271   2.711155                   0   \n",
       "132545     2.447271   2.711155                   0   \n",
       "\n",
       "          Cardiac Surgery Recovery Unit  Medical ICU  Surgical ICU  \n",
       "recordid                                                            \n",
       "132539                                0            0             1  \n",
       "132540                                1            0             0  \n",
       "132541                                0            1             0  \n",
       "132543                                0            1             0  \n",
       "132545                                0            1             0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AdaBoostClassifier --> VarianceThreshold: 0 and PCA: 60 has a score of 0.6210511982570807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AdaBoostClassifier --> VarianceThreshold: 0 and PCA: 70 has a score of 0.6245234204793028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AdaBoostClassifier --> VarianceThreshold: 0.5 and PCA: 60 has a score of 0.6229575163398693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AdaBoostClassifier --> VarianceThreshold: 0.5 and PCA: 70 has a score of 0.6169662309368192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (45, 45) VarianceThreshold: 0 and PCA: 60 has a score of 0.6131535947712419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (100,) VarianceThreshold: 0 and PCA: 60 has a score of 0.6645901416122004\n",
      "Using MLPClassifier --> HiddenLayer: (30, 30, 30) VarianceThreshold: 0 and PCA: 60 has a score of 0.6532543572984749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (45, 45) VarianceThreshold: 0 and PCA: 70 has a score of 0.6619349128540305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (100,) VarianceThreshold: 0 and PCA: 70 has a score of 0.6210511982570807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (30, 30, 30) VarianceThreshold: 0 and PCA: 70 has a score of 0.6054261982570806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (45, 45) VarianceThreshold: 0.5 and PCA: 60 has a score of 0.6334763071895425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (100,) VarianceThreshold: 0.5 and PCA: 60 has a score of 0.6359613289760349\n",
      "Using MLPClassifier --> HiddenLayer: (30, 30, 30) VarianceThreshold: 0.5 and PCA: 60 has a score of 0.6389229302832243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (45, 45) VarianceThreshold: 0.5 and PCA: 70 has a score of 0.6427696078431372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (100,) VarianceThreshold: 0.5 and PCA: 70 has a score of 0.6697984749455338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier --> HiddenLayer: (30, 30, 30) VarianceThreshold: 0.5 and PCA: 70 has a score of 0.6271446078431372\n",
      "Using GaussianNB --> VarianceThreshold: 0 and PCA: 60 has a score of 0.6267701525054465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GaussianNB --> VarianceThreshold: 0 and PCA: 70 has a score of 0.6165236928104575\n",
      "Using GaussianNB --> VarianceThreshold: 0.5 and PCA: 60 has a score of 0.6285062636165577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GaussianNB --> VarianceThreshold: 0.5 and PCA: 70 has a score of 0.6287105119825709\n",
      "Using LinearRegression --> VarianceThreshold: 0 and PCA: 60 has a score of 184.70402360476908\n",
      "Using LinearRegression --> VarianceThreshold: 0 and PCA: 70 has a score of 185.08289301443173\n",
      "Using LinearRegression --> VarianceThreshold: 0.5 and PCA: 60 has a score of 186.7697827186973\n",
      "Using LinearRegression --> VarianceThreshold: 0.5 and PCA: 70 has a score of 186.753853073938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(1) --> SelectKBest: 90 and PCA: 60 has a score of 321.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(3) --> SelectKBest: 90 and PCA: 60 has a score of 271.2871933333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(1) --> SelectKBest: 90 and PCA: 70 has a score of 298.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(3) --> SelectKBest: 90 and PCA: 70 has a score of 273.6184630555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(1) --> SelectKBest: 90 and PCA: 60 has a score of 319.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(3) --> SelectKBest: 90 and PCA: 60 has a score of 272.36566833333336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(1) --> SelectKBest: 90 and PCA: 70 has a score of 281.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DecisionTreeRegressor(3) --> SelectKBest: 90 and PCA: 70 has a score of 281.55253722222227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((45, 45)) --> SelectKBest: 90 and PCA: 60 has a score of 274.21497222587874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((100,)) --> SelectKBest: 90 and PCA: 60 has a score of 267.1386902281254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((30, 30, 30)) --> SelectKBest: 90 and PCA: 60 has a score of 285.8242815703894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((45, 45)) --> SelectKBest: 90 and PCA: 70 has a score of 310.52472818168707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((100,)) --> SelectKBest: 90 and PCA: 70 has a score of 299.1450702919346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((30, 30, 30)) --> SelectKBest: 90 and PCA: 70 has a score of 242.02005623740197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((45, 45)) --> SelectKBest: 90 and PCA: 60 has a score of 312.9529569390459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((100,)) --> SelectKBest: 90 and PCA: 60 has a score of 271.50670143914505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((30, 30, 30)) --> SelectKBest: 90 and PCA: 60 has a score of 240.95001460555883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((45, 45)) --> SelectKBest: 90 and PCA: 70 has a score of 278.82706209138405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((100,)) --> SelectKBest: 90 and PCA: 70 has a score of 318.93088574069856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPRegressor((30, 30, 30)) --> SelectKBest: 90 and PCA: 70 has a score of 253.7287779166953\n",
      "\n",
      "\n",
      "Testing on Fold 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8de40ed0747c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mput_single_into_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0my_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_ans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recordid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'days_in_hospital'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mortality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mx_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_x_for_design_matrix_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0my_linear_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recordid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mortality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-86284a0bd097>\u001b[0m in \u001b[0;36mpreprocess_x_for_design_matrix_2\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mhour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mparameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecordId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ICUType'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m                     \u001b[0msetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36msetter\u001b[1;34m(item, v)\u001b[0m\n\u001b[0;32m    536\u001b[0m                     \u001b[1;31m# set the item, possibly having a dtype change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5802\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5803\u001b[0m         \"\"\"\n\u001b[1;32m-> 5804\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5805\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[1;32m--> 734\u001b[1;33m                           do_integrity_check=False)\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bin_feat = [\"Gender\", \"Coronary Care Unit\", \"Cardiac Surgery Recovery Unit\", \"Medical ICU\", \"Surgical ICU\"]\n",
    "non_bin_feat = []\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    remainder = 'passthrough',\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), non_bin_feat)])\n",
    "\n",
    "parameters = {'VarianceThreshold':[0,0.5], 'PCA':[60,70],\n",
    "              'SelectKBest':[80, 90],\n",
    "              'DecisionTreeRegressor_min_samples_leaf':[1,3],\n",
    "              'MLPRegressor_hiddenLayer':[(45,45,), (100,), (30,30,30)]\n",
    "             }\n",
    "\n",
    "all_list = [1,2,3,4]\n",
    "for i in range(1,5):\n",
    "    print(\"Testing on Fold\", i)\n",
    "    x_train_df = pd.DataFrame()\n",
    "    y_train_df = pd.DataFrame()\n",
    "    \n",
    "    # Getting train data set up\n",
    "    for j in [x for x in all_list if x != i]: \n",
    "        string = \"../Project_Data/Fold\"+str(j)\n",
    "        y_file = \"../Project_Data/Fold\"+str(j)+\"_Outcomes.csv\"\n",
    "        x_train_df = x_train_df.append(put_single_into_dataframe(read_text(string)))\n",
    "        y_train_df = y_train_df.append(pd.DataFrame(read_ans(y_file), columns=['recordid', 'days_in_hospital', 'mortality']))\n",
    "    x_train_df = preprocess_x_for_design_matrix_2(x_train_df)\n",
    "    y_linear_train_df = y_train_df.drop(['recordid','mortality'], axis=1)\n",
    "    for index, row in y_train_df.iterrows():\n",
    "        if row['days_in_hospital'] == -1:\n",
    "            row['days_in_hospital'] = 2\n",
    "    y_linear_train_df['days_in_hospital'] = pd.to_numeric(y_linear_train_df['days_in_hospital'])\n",
    "    y_classification_train_df = y_train_df.drop(['recordid','days_in_hospital'], axis=1)\n",
    "    y_classification_train_df['mortality'] = pd.to_numeric(y_classification_train_df['mortality'])\n",
    "        \n",
    "    # Getting test data set up\n",
    "    x_test_df = put_single_into_dataframe(read_text(\"../Project_Data/Fold\"+str(i)))\n",
    "    x_test_df = preprocess_x_for_design_matrix_2(x_test_df)\n",
    "    y_test_df = pd.DataFrame(read_ans(\"../Project_Data/Fold\"+str(i)+\"_Outcomes.csv\"), columns=['recordid', 'days_in_hospital', 'mortality'])\n",
    "    y_linear_test_df = y_test_df.drop(['recordid','mortality'], axis=1)\n",
    "    for index, row in y_test_df.iterrows():\n",
    "        if row['days_in_hospital'] == -1:\n",
    "            row['days_in_hospital'] = 2\n",
    "    y_linear_test_df['days_in_hospital'] = pd.to_numeric(y_linear_test_df['days_in_hospital'])\n",
    "    y_classification_test_df = y_test_df.drop(['recordid','days_in_hospital'], axis=1)\n",
    "    y_classification_test_df['mortality'] = pd.to_numeric(y_classification_test_df['mortality'])\n",
    "        \n",
    "    \n",
    "    # Creating regression model and parameters to try out\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            est = Pipeline(steps=[\n",
    "            ('scaler', scaler),\n",
    "            ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "            ('dim_reducer', PCA(n_components = nN_components)),\n",
    "            ('classifier', LinearRegression())])\n",
    "            est.fit(x_train_df, y_linear_train_df)\n",
    "            prediction = est.predict(x_test_df)\n",
    "            print ( \"Using LinearRegression --> VarianceThreshold: {} and PCA: {} has a score of {}\".format(nThreshold, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"SelectKBest\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            for min_samples_leaf in parameters[\"DecisionTreeRegressor_min_samples_leaf\"]:\n",
    "                est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', SelectKBest(k = 90)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', DecisionTreeRegressor(min_samples_leaf = min_samples_leaf))])\n",
    "                est.fit(x_train_df, y_linear_train_df)\n",
    "                prediction = est.predict(x_test_df)\n",
    "                print ( \"Using DecisionTreeRegressor({}) --> SelectKBest: 90 and PCA: {} has a score of {}\".format(min_samples_leaf, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    for nThreshold in parameters[\"VarianceThreshold\"]:\n",
    "        for nN_components in parameters[\"PCA\"]:\n",
    "            for hiddenLayer in parameters[\"MLPRegressor_hiddenLayer\"]:\n",
    "                est = Pipeline(steps=[\n",
    "                ('scaler', scaler),\n",
    "                ('f_selecter', VarianceThreshold(threshold = nThreshold)),\n",
    "                ('dim_reducer', PCA(n_components = nN_components)),\n",
    "                ('classifier', MLPRegressor(hidden_layer_sizes = hiddenLayer, learning_rate_init = 0.01))])\n",
    "                est.fit(x_train_df, y_linear_train_df)\n",
    "                prediction = est.predict(x_test_df)\n",
    "                print ( \"Using MLPRegressor({}) --> SelectKBest: 90 and PCA: {} has a score of {}\".format(hiddenLayer, nN_components, mean_squared_error(y_linear_test_df, prediction)) )\n",
    "    print(end=\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
